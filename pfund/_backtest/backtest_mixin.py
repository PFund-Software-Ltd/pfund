from __future__ import annotations
from typing import TYPE_CHECKING, overload
if TYPE_CHECKING:
    import torch
    import pandas as pd
    import polars as pl
    from pfeed.typing import GenericFrame
    from pfeed.enums import DataSource
    from pfund.typing import ModelT
    from pfund.enums import TradingVenue
    from pfund.datas.data_base import BaseData
    from pfund.datas.data_time_based import TimeBasedData
    from pfund.utils.dataset_splitter import DatasetPeriods, CrossValidatorDatasetPeriods

from functools import cached_property

import numpy as np

from pfund_kit.style import cprint
from pfund.components.strategies.strategy_base import BaseStrategy
from pfund.components.models.model_base import BaseModel
from pfund.datas.data_config import DataConfig
from pfund.enums import BacktestMode


# TODO use functools wrap?
def vectorized(func):
    def wrapper(*args, **kwargs):
        # FIXME
        self: BacktestMixin | BaseStrategy | BaseModel = args[0]
        if self.backtest_mode == BacktestMode.vectorized:
            return func(*args, **kwargs)
        else:
            raise Exception(f"{func.__name__}() is only available in vectorized backtesting.")
    return wrapper


# TODO
def hybrid(func):
    pass


def event_driven(func):
    def wrapper(*args, **kwargs):
        # FIXME
        self: BacktestMixin | BaseStrategy | BaseModel = args[0]
        if self.backtest_mode == BacktestMode.event_driven:
            return func(*args, **kwargs)
        else:
            raise Exception(f"{func.__name__}() is only available in event driven backtesting.")
    return wrapper


class BacktestMixin:
    # NOTE: used to keep the MRO clean, only the __init__ of a non-mixin class is called
    def __mixin_post_init__(self: BacktestMixin | BaseStrategy | BaseModel, *args, **kwargs):
        super().__mixin_post_init__(*args, **kwargs)  # calling ComponentMixin.__mixin_post_init__()

        # NOTE: signal_df = INDEX columns + signals generated by the current strategy/model
        self._signal_df = None
        self._signal_list = []
        self._signal_list_num = 0
            
        self._is_dummy_strategy = False
        
    @property
    def backtest_mode(self: BacktestMixin | BaseStrategy | BaseModel) -> BacktestMode:
        return self._context.backtest.backtest_mode
    
    @property
    def dataset_periods(self: BacktestMixin | BaseStrategy | BaseModel) -> DatasetPeriods | list[CrossValidatorDatasetPeriods]:
        return self._context.backtest.dataset_splitter.dataset_periods
    
    @cached_property
    def _is_signal_df_required(self: BacktestMixin | BaseStrategy | BaseModel) -> bool:
        if self._is_dummy_strategy:
            return False
        elif self.backtest_mode == BacktestMode.vectorized:
            return True
        elif self.backtest_mode == BacktestMode.event_driven:
            return self.settings.reuse_signals
    
    @cached_property
    def _is_append_to_df(self: BacktestMixin | BaseStrategy | BaseModel):
        if isinstance(self, BaseStrategy):
            return not self._is_signal_df_required and not self._is_dummy_strategy
        else:
            return not self._is_signal_df_required
    
    # TODO
    @property
    def train_set(self: BaseStrategy | BaseModel) -> GenericFrame:
        # FIXME: should use pfeed's config?
        storage_config = BacktestEngine._storage_config
        return self.store.load_data_from_storage(
            storage=storage_config.storage,
            storage_options=storage_config.storage_options,
        )
    
    # TODO
    @property
    def dev_set(self: BaseStrategy | BaseModel) -> GenericFrame:
        return self.store.load_data(...)
    val_set = dev_set
    
    # TODO
    @property
    def test_set(self: BaseStrategy | BaseModel) -> GenericFrame:
        return self.store.load_data(...)
    
    def on_stop(self: BaseStrategy | BaseModel):
        super().on_stop()
        if self.backtest_mode == BacktestMode.event_driven and self.settings.assert_signals and self._has_signal_df():
            self._assert_consistent_signals()
            
    def _next(self: BacktestMixin | BaseStrategy | BaseModel, data: BaseData) -> torch.Tensor | np.ndarray:
        if not self._is_signal_df_required:
            new_pred = super()._next(data)
        else:
            new_pred = self._signal_list[self._signal_list_num]
            self._signal_list_num += 1
        return new_pred
    
    def set_flags(self: BacktestMixin | BaseStrategy | BaseModel, is_dummy_strategy: bool):
        # case1: strategy is a dummy strategy
        # case2: model is using a dummy strategy as its only consumer
        self._is_dummy_strategy = is_dummy_strategy
        self._is_signal_df_required = self._check_if_signal_df_required()
        self._is_append_to_df = self._check_if_append_to_df()
    
    def _append_to_df(self: BacktestMixin | BaseStrategy | BaseModel, data: BaseData, **kwargs):
        if self._is_append_to_df:
            return self.data_tool.append_to_df(data, self.predictions, **kwargs)
    
    def _has_signal_df(self: BacktestMixin | BaseStrategy | BaseModel):
        return ( isinstance(self, BaseStrategy) and self.is_sub_strategy() ) or isinstance(self, BaseModel)
    
    def signalize(
        self: BacktestMixin | BaseStrategy | BaseModel, 
        X: pd.DataFrame | pl.LazyFrame,
        pred_y: torch.Tensor | np.ndarray,
    ) -> pd.DataFrame | pl.LazyFrame:
        try:
            import torch
        except ImportError:
            torch = None
        if torch is not None and isinstance(pred_y, torch.Tensor):
            pred_y = pred_y.detach().numpy() if pred_y.requires_grad else pred_y.numpy()
        signal_cols = self.get_signal_cols()
        signal_df: pd.DataFrame | pl.LazyFrame = self.data_tool.signalize(X, pred_y, columns=signal_cols)
        return signal_df
    
    def _set_signal_df(self: BacktestMixin | BaseStrategy | BaseModel, signal_df: pd.DataFrame | pl.LazyFrame):
        assert signal_df.shape[0] == self.df.shape[0], f"{signal_df.shape[0]=} != {self.df.shape[0]=}"
        nan_columns = self.data_tool.get_nan_columns(signal_df)
        assert not nan_columns, f"{self.name} signal_df has all NaN values in columns: {nan_columns}"
        self._signal_list = signal_df.drop(columns=self.INDEX).to_numpy().tolist()
        self._signal_df = signal_df
    
    @event_driven
    def _assert_consistent_signals(self: BacktestMixin | BaseStrategy | BaseModel):
        '''Asserts consistent signals from vectorized and event-driven backtesting, triggered in event-driven backtesting'''
        from pfeed.enums import DataTool

        self.logger.debug(f"asserting {self.name}'s signals...")
        
        # since current strategy/model's signal_df is its consumer's prediction column
        # get the signal_df from the consumer
        consumer_df = self._consumer.df

        # load the signal_df dumped from vectorized backtesting
        self._is_signal_df_required = True
        self.load()

        if self.data_tool.name == DataTool.pandas:
            event_driven_signal_df = consumer_df[self.INDEX + self._signal_cols]
            # NOTE: since the loaded signal_df might have a few more rows than event_driven_signal_df
            # because the last bar is not pushed in event-driven backtesting.
            # truncate the signal_df to the same length as event_driven_signal_df
            vectorized_signal_df = self._signal_df.iloc[:len(event_driven_signal_df)]
        elif self.data_tool.name == DataTool.polars:
            event_driven_signal_df = consumer_df.select(self.INDEX + self._signal_cols)
            vectorized_signal_df = self._signal_df.slice(0, len(event_driven_signal_df))
        # TODO
        else:
            raise NotImplementedError
        self.data_tool.assert_frame_equal(vectorized_signal_df, event_driven_signal_df)

    def _prepare_df(self: BacktestMixin | BaseStrategy | BaseModel):
        if self._is_dummy_strategy and isinstance(self, BaseStrategy):
            return
        ts_col_type = 'timestamp' if self.backtest_mode == BacktestMode.event_driven else 'datetime'
        self.data_tool.prepare_df(ts_col_type=ts_col_type)
        if self._is_signal_df_required:
            self._merge_signal_dfs_with_df()
    
    def _merge_signal_dfs_with_df(self: BacktestMixin | BaseStrategy | BaseModel):
        '''Merge df with signal dfs from all listeners (strategies/models)'''
        if isinstance(self, BaseStrategy):
            if signal_dfs := [strategy._signal_df for strategy in self.strategies.values()]:
                self.data_tool.merge_signal_dfs_with_df(signal_dfs)
        if signal_dfs := [model._signal_df for model in self.models.values()]:
            self.data_tool.merge_signal_dfs_with_df(signal_dfs)
    
    def clear_dfs(self: BacktestMixin | BaseStrategy | BaseModel):
        assert self.backtest_mode == BacktestMode.event_driven
        if not self._is_signal_df_required:
            self.data_tool.clear_df()
        if isinstance(self, BaseStrategy):
            for strategy in self.strategies.values():
                strategy.clear_dfs()
        for model in self.models.values():
            model.clear_dfs()
    
    # TODO: add data_generator to add_data()
    def add_data(
        self: BaseStrategy | BaseModel, 
        trading_venue: TradingVenue, 
        product: str,
        data_source: DataSource | None=None,
        from_storage: tStorage | None=None,
        data_config: DataConfig | None=None,
        **product_specs
    ) -> list[BaseData]:
        # REVIEW
        def _force_primary_resolution_as_resampler(data_config: DataConfig):
            '''force using the primary resolution as a resampler for any extra resolutions that are <= primary resolution
            e.g. resolution='1m', extra_resolutions=['1h'], force 'resample' to be {'1h': '1m'}
            since in live trading, multiple data resolutions can be subscribed, i.e. data of '1h' and '1m' can be both subscribed,
            but in backtesting, only the primary resolution will be used for event-driven backtesting, 
            so need to force 'resample' to be {'1h': '1m'}
            '''
            extra_resolutions = data_config.get('extra_resolutions', [])
            primary_resolution = self._resolution
            for resolution in extra_resolutions:
                if resolution < primary_resolution:
                    if resolution._value() % primary_resolution._value() == 0:
                        data_config['resample'][resolution] = primary_resolution
                    else:
                        raise Exception(f'extra_resolution={resolution} is not supported for auto_resampling, since it is not a multiple of resolution={primary_resolution}')
        # REVIEW
        def _set_default_skip_first_bar(data_config: DataConfig):
            extra_resolutions = data_config.get('extra_resolutions', [])
            primary_resolution = self._resolution
            skip_first_bar = data_config.get('skip_first_bar', {})
            shift = data_config.get('shift', {})
            bar_resolutions = [resolution for resolution in [primary_resolution] + extra_resolutions if resolution.is_bar()]
            for resolution in bar_resolutions:
                # In backtesting, the first bar might be incomplete due to shifting 
                # e.g. hourly bar shifts 30 minutes, first bar is 00:00 to 00:30, which is incomplete
                if resolution not in skip_first_bar and resolution in shift:
                    skip_first_bar[resolution] = True
            
        if data_config:
            _force_primary_resolution_as_resampler(data_config)
            _set_default_skip_first_bar(data_config)
            
        datas: list[TimeBasedData] = super().add_data(trading_venue, product, data_source=data_source, from_storage=from_storage, data_config=data_config, **product_specs)
        use_tick_or_quote = any(data.resolution.is_tick() or data.resolution.is_quote() for data in datas)
        if use_tick_or_quote:
            cprint('WARNING: tick data and quote data will be ignored in backtesting', style='bold red')
        return datas
    
    @overload
    def dump(self: BacktestMixin | BaseStrategy | BaseModel, signal_df: pd.DataFrame | pl.LazyFrame): ...
        
    def add_model(
        self: BaseStrategy | BaseModel, 
        model: ModelT, 
        name: str='',
        min_data: int | None=None,
        max_data: int | None=None,
        group_data: bool=True,
        signal_cols: list[str] | None=None,
    ) -> BacktestMixin | ModelT:
        from pfund.components.models.model_backtest import BacktestModel
        name = name or model.get_default_name()
        model = BacktestModel(type(model), model.model, *model._args, **model._kwargs)
        return super().add_model(
            model, 
            name=name, 
            min_data=min_data, 
            max_data=max_data, 
            group_data=group_data,
            signal_cols=signal_cols,
        )
