# pyright: reportUninitializedInstanceVariable=false
from __future__ import annotations
from typing import TYPE_CHECKING, overload, cast, Any
if TYPE_CHECKING:
    import torch
    import pandas as pd
    import polars as pl
    from pfeed.typing import GenericFrame
    from pfund._backtest.typing import BacktestDataFrame
    from pfund.typing import ModelT
    from pfund.entities.products.product_base import BaseProduct
    from pfund.datas.data_base import BaseData
    from pfund.components.mixin import ComponentMixin
    from pfund.engines.engine_context import EngineContext
    from pfund.engines.backtest_engine import BacktestEngineContext
    from pfund.engines.settings.backtest_engine_settings import BacktestEngineSettings
    from pfund.utils.dataset_splitter import DatasetPeriods, CrossValidatorDatasetPeriods

import logging
from functools import cached_property

import numpy as np

from pfund_kit.style import cprint, RichColor, TextStyle
from pfund.components.strategies.strategy_base import BaseStrategy
from pfund.components.models.model_base import BaseModel
from pfund.datas.data_config import DataConfig
from pfund.enums import BacktestMode


# TODO use functools wrap?
def vectorized(func):
    def wrapper(*args, **kwargs):
        # FIXME
        self = args[0]
        if self.backtest_mode == BacktestMode.VECTORIZED:
            return func(*args, **kwargs)
        else:
            raise Exception(f"{func.__name__}() is only available in vectorized backtesting.")
    return wrapper


# TODO
def hybrid(func):
    pass


def event_driven(func):
    def wrapper(*args, **kwargs):
        # FIXME
        self = args[0]
        if self.backtest_mode == BacktestMode.EVENT_DRIVEN:
            return func(*args, **kwargs)
        else:
            raise Exception(f"{func.__name__}() is only available in event driven backtesting.")
    return wrapper


class BacktestMixin:
    _context: EngineContext | None
    logger: logging.Logger
    
    # NOTE: used to keep the MRO clean, only the __init__ of a non-mixin class is called
    def __mixin_post_init__(self, *args: Any, **kwargs: Any):
        cast("ComponentMixin", super()).__mixin_post_init__(*args, **kwargs)

        # NOTE: signal_df = INDEX columns + signals generated by the current strategy/model
        self._signal_df = None
        self._signal_list = []
        self._signal_list_num = 0
            
        self._is_dummy_strategy = False

    def backtest(self, df: BacktestDataFrame):  # pyright: ignore[reportUnknownParameterType,reportUnusedParameter]
        raise NotImplementedError(f'{self.name} does not have a backtest() method, cannot run vectorized backtesting')
    
    @property
    def context(self) -> BacktestEngineContext:
        assert self._context is not None, 'context is not set'
        return cast("BacktestEngineContext", self._context)
        
    @property
    def settings(self) -> BacktestEngineSettings:
        return cast("BacktestEngineSettings", self.context.settings)
    
    @property
    def backtest_mode(self) -> BacktestMode:
        return self.context.backtest.backtest_mode
    
    @property
    def dataset_periods(self) -> DatasetPeriods | list[CrossValidatorDatasetPeriods]:
        return self.context.backtest.dataset_splitter.dataset_periods
    
    @cached_property
    def _is_signal_df_required(self) -> bool:
        if self._is_dummy_strategy:
            return False
        elif self.backtest_mode == BacktestMode.VECTORIZED:
            return True
        elif self.backtest_mode == BacktestMode.EVENT_DRIVEN:
            return self.settings.reuse_signals
        # TODO: handle hybrid backtesting
        else:
            raise ValueError(f"{self.backtest_mode=} is not supported")
    
    @cached_property
    def _is_append_to_df(self) -> bool:
        if isinstance(self, BaseStrategy):
            return not self._is_signal_df_required and not self._is_dummy_strategy
        else:
            return not self._is_signal_df_required
    
    # TODO
    @property
    def train_set(self) -> GenericFrame:
        # FIXME: should use pfeed's config?
        storage_config = BacktestEngine._storage_config
        return self.store.load_data_from_storage(
            storage=storage_config.storage,
            storage_options=storage_config.storage_options,
        )
    
    # TODO
    @property
    def dev_set(self) -> GenericFrame:
        return self.store.load_data(...)
    val_set = dev_set
    
    # TODO
    @property
    def test_set(self) -> GenericFrame:
        return self.store.load_data(...)
    
    def on_stop(self):
        super().on_stop()
        if self.backtest_mode == BacktestMode.EVENT_DRIVEN and self.settings.assert_signals and self._has_signal_df():
            self._assert_consistent_signals()
            
    def _next(self, data: BaseData) -> torch.Tensor | np.ndarray:
        if not self._is_signal_df_required:
            new_pred = super()._next(data)
        else:
            new_pred = self._signal_list[self._signal_list_num]
            self._signal_list_num += 1
        return new_pred
    
    def set_flags(self, is_dummy_strategy: bool):
        # case1: strategy is a dummy strategy
        # case2: model is using a dummy strategy as its only consumer
        self._is_dummy_strategy = is_dummy_strategy
        self._is_signal_df_required = self._check_if_signal_df_required()
        self._is_append_to_df = self._check_if_append_to_df()
    
    def _append_to_df(self, data: BaseData, **kwargs: Any):
        if self._is_append_to_df:
            return self.data_tool.append_to_df(data, self.predictions, **kwargs)
    
    def _has_signal_df(self) -> bool:
        return ( isinstance(self, BaseStrategy) and self.is_sub_strategy() ) or isinstance(self, BaseModel)
    
    def signalize(
        self, 
        X: pd.DataFrame | pl.LazyFrame,
        pred_y: torch.Tensor | np.ndarray,
    ) -> pd.DataFrame | pl.LazyFrame:
        try:
            import torch
        except ImportError:
            torch = None
        if torch is not None and isinstance(pred_y, torch.Tensor):
            pred_y = pred_y.detach().numpy() if pred_y.requires_grad else pred_y.numpy()
        signal_cols = self.get_signal_cols()
        signal_df: pd.DataFrame | pl.LazyFrame = self.data_tool.signalize(X, pred_y, columns=signal_cols)
        return signal_df
    
    def _set_signal_df(self, signal_df: pd.DataFrame | pl.LazyFrame):
        assert signal_df.shape[0] == self.df.shape[0], f"{signal_df.shape[0]=} != {self.df.shape[0]=}"
        nan_columns = self.data_tool.get_nan_columns(signal_df)
        assert not nan_columns, f"{self.name} signal_df has all NaN values in columns: {nan_columns}"
        self._signal_list = signal_df.drop(columns=self.INDEX).to_numpy().tolist()
        self._signal_df = signal_df
    
    @event_driven
    def _assert_consistent_signals(self):
        '''Asserts consistent signals from vectorized and event-driven backtesting, triggered in event-driven backtesting'''
        from pfeed.enums import DataTool

        self.logger.debug(f"asserting {self.name}'s signals...")
        
        # since current strategy/model's signal_df is its consumer's prediction column
        # get the signal_df from the consumer
        consumer_df = self._consumer.df

        # load the signal_df dumped from vectorized backtesting
        self._is_signal_df_required = True
        self.load()

        if self.data_tool.name == DataTool.pandas:
            event_driven_signal_df = consumer_df[self.INDEX + self._signal_cols]
            # NOTE: since the loaded signal_df might have a few more rows than event_driven_signal_df
            # because the last bar is not pushed in event-driven backtesting.
            # truncate the signal_df to the same length as event_driven_signal_df
            vectorized_signal_df = self._signal_df.iloc[:len(event_driven_signal_df)]
        elif self.data_tool.name == DataTool.polars:
            event_driven_signal_df = consumer_df.select(self.INDEX + self._signal_cols)
            vectorized_signal_df = self._signal_df.slice(0, len(event_driven_signal_df))
        # TODO
        else:
            raise NotImplementedError
        self.data_tool.assert_frame_equal(vectorized_signal_df, event_driven_signal_df)

    def _prepare_df(self):
        if self._is_dummy_strategy and isinstance(self, BaseStrategy):
            return
        ts_col_type = 'timestamp' if self.backtest_mode == BacktestMode.EVENT_DRIVEN else 'datetime'
        self.data_tool.prepare_df(ts_col_type=ts_col_type)
        if self._is_signal_df_required:
            self._merge_signal_dfs_with_df()
    
    def _merge_signal_dfs_with_df(self):
        '''Merge df with signal dfs from all listeners (strategies/models)'''
        if isinstance(self, BaseStrategy):
            if signal_dfs := [strategy._signal_df for strategy in self.strategies.values()]:
                self.data_tool.merge_signal_dfs_with_df(signal_dfs)
        if signal_dfs := [model._signal_df for model in self.models.values()]:
            self.data_tool.merge_signal_dfs_with_df(signal_dfs)
    
    def clear_dfs(self):
        assert self.backtest_mode == BacktestMode.EVENT_DRIVEN
        if not self._is_signal_df_required:
            self.data_tool.clear_df()
        if isinstance(self, BaseStrategy):
            for strategy in self.strategies.values():
                strategy.clear_dfs()
        for model in self.models.values():
            model.clear_dfs()
    
    def _resolve_data_config(self, product: BaseProduct, data_config: DataConfig | None) -> DataConfig:
        data_config = cast("ComponentMixin", super())._resolve_data_config(product, data_config)
        # extra_resolutions are not always supported in backtesting, print out warnings
        if data_config.extra_resolutions:
            if self.backtest_mode != BacktestMode.EVENT_DRIVEN:
                cprint(
                    f'{product.name} extra_resolutions={data_config.extra_resolutions} will be ignored in {self.backtest_mode.value} backtesting',
                    style=TextStyle.BOLD + RichColor.RED
                )
            else:
                # REVIEW: support looping quote/tick data?
                if any(resolution.is_quote() or resolution.is_tick() for resolution in data_config.resolutions):
                    cprint(
                        f'WARNING: {product.name} tick/quote data will be ignored in backtesting',
                        style=TextStyle.BOLD + RichColor.RED
                    )
        return data_config
    
    def _auto_resample_data_config(self, product: BaseProduct, data_config: DataConfig) -> DataConfig:
        '''Automatically configures resampling for backtesting.

        Overrides ComponentMixin._auto_resample_data_config() to force resampling setup for
        any extra resolutions that are lower (less granular) than the primary resolution.

        Backtesting Constraint:
            In live trading, multiple data resolutions can be subscribed independently
            (e.g., both 1m and 1h data streams). However, in backtesting, only the primary
            resolution is used for event-driven simulation. Any lower resolutions must be
            generated by resampling/aggregating from the primary resolution.

        Resolution Comparison (pfund convention):
            - Higher resolution (more granular, e.g., '1m') is considered "greater"
            - Lower resolution (less granular, e.g., '1h') is considered "less"
            - Therefore: '1h' < '1m' evaluates to True

        Example:
            Given:  primary_resolution='1m', extra_resolutions=['1h']
            Result: resample={'1h': '1m'}
            Meaning: Aggregate sixty 1m bars into one 1h bar during backtesting

        Args:
            product: The product being backtested
            data_config: Configuration containing resolutions and resampling rules

        Returns:
            Updated DataConfig with automatic resampling configured

        Raises:
            Exception: If a lower resolution cannot be evenly resampled from the primary
                      resolution (e.g., '1h' cannot be cleanly resampled from '45m')
        '''
        # Only event-driven mode supports extra resolutions
        if self.backtest_mode != BacktestMode.EVENT_DRIVEN:
            return data_config  # Skip processing extra resolutions

        original_resample = data_config.resample.copy()
        primary_resolution = data_config.primary_resolution
        for resolution in data_config.resolutions:
            if resolution == primary_resolution:
                continue
            # REVIEW: support using tick data to resample bar data?
            if not resolution.is_bar():
                continue
            if resolution < primary_resolution:
                if resolution.to_seconds() % primary_resolution.to_seconds() == 0:
                    data_config.resample[resolution] = primary_resolution
                    self.logger.warning(
                        f'{product.name} is auto-resampled from {original_resample} to {data_config.resample} in backtesting'
                    )
                else:
                    raise Exception(f'{resolution=} is not supported in backtesting because it cannot be resampled by resolution={primary_resolution}')
            else:
                raise ValueError(f'extra resolution {resolution} higher than primary resolution {primary_resolution} is not allowed in backtesting')
        return data_config
    
    @overload
    def dump(self, signal_df: pd.DataFrame | pl.LazyFrame): ...
        
    def add_model(
        self, 
        model: ModelT, 
        name: str='',
        min_data: int | None=None,
        max_data: int | None=None,
        group_data: bool=True,
        signal_cols: list[str] | None=None,
    ) -> BacktestMixin | ModelT:
        from pfund.components.models.model_backtest import BacktestModel
        name = name or model.get_default_name()
        model = BacktestModel(type(model), model.model, *model._args, **model._kwargs)
        return super().add_model(
            model, 
            name=name, 
            min_data=min_data, 
            max_data=max_data, 
            group_data=group_data,
            signal_cols=signal_cols,
        )
